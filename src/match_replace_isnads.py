# -*- coding: utf-8 -*-
"""match_replace_isnads.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h3kmaTxwxCPF27fDEqxk-c1njlWNTZer
"""

#!/usr/bin/env python3
# Colab-Friendly Network Name Processor
# Processes network pathways with time steps and replaces node names

import pandas as pd
import numpy as np
import os
import re
from collections import defaultdict

class NetworkNameProcessor:
    """
    Class for processing network names and replacing them based on a mapping.
    """
    def __init__(self, names_file, nodelist_file, output_file=None):
        """
        Initialize the processor with file paths.

        Args:
            names_file (str): Path to the CSV file with network pathways
            nodelist_file (str): Path to the CSV file with node name mappings
            output_file (str): Path to the output file (default: names_replaced.csv)
        """
        self.names_file = names_file
        self.nodelist_file = nodelist_file
        self.output_file = output_file or 'names_replaced.csv'

        # Data storage
        self.names_df = None
        self.nodelist_df = None
        self.mapping_dict = None
        self.time_columns = None

        # Statistics
        self.stats = {
            'total_names': 0,
            'replaced_names': 0,
            'unmatched_names': set()
        }

    def load_data(self):
        """
        Load the necessary data files.

        Returns:
            bool: True if successful, False otherwise
        """
        try:
            print(f"Loading names file: {self.names_file}")
            self.names_df = pd.read_csv(self.names_file)

            print(f"Loading nodelist file: {self.nodelist_file}")
            self.nodelist_df = pd.read_csv(self.nodelist_file)

            print(f"Loaded {len(self.names_df)} pathways and {len(self.nodelist_df)} node mappings")
            return True
        except Exception as e:
            print(f"Error loading data: {e}")
            return False

    def identify_time_columns(self):
        """
        Identify the time step columns in the names dataframe.

        Returns:
            list: List of column names representing time steps
        """
        # Find columns that match the pattern t0, t-1, t-2, etc.
        time_columns = [col for col in self.names_df.columns
                        if col.startswith('t') and (col == 't0' or col.startswith('t-'))]

        # Sort them in chronological order
        def time_key(col):
            if col == 't0':
                return 0
            return -int(col.split('-')[1])

        time_columns.sort(key=time_key)

        print(f"Identified {len(time_columns)} time columns: {', '.join(time_columns)}")
        self.time_columns = time_columns
        return time_columns

    def create_mapping(self):
        """
        Create a mapping dictionary from short_name to name_replace.

        Returns:
            dict: Mapping dictionary
        """
        # Check if the required columns exist
        if 'short_name' not in self.nodelist_df.columns or 'name_replace' not in self.nodelist_df.columns:
            available_cols = ', '.join(self.nodelist_df.columns)
            print(f"Required columns 'short_name' and/or 'name_replace' not found in nodelist. Available columns: {available_cols}")
            if 'name_replace' not in self.nodelist_df.columns and len(self.nodelist_df.columns) >= 2:
                # Assume the second column is the replacement
                print(f"Using '{self.nodelist_df.columns[1]}' as the replacement column")
                self.mapping_dict = dict(zip(self.nodelist_df['short_name'], self.nodelist_df[self.nodelist_df.columns[1]]))
            else:
                self.mapping_dict = {}
            return self.mapping_dict

        # Create the mapping dictionary
        self.mapping_dict = dict(zip(self.nodelist_df['short_name'], self.nodelist_df['name_replace']))
        print(f"Created mapping dictionary with {len(self.mapping_dict)} entries")

        # Check for duplicates in the mapping
        short_name_counts = self.nodelist_df['short_name'].value_counts()
        duplicates = short_name_counts[short_name_counts > 1].index.tolist()
        if duplicates:
            print(f"Found {len(duplicates)} duplicate short_names in the nodelist")
            for dup in duplicates[:5]:  # Show first 5 duplicates
                print(f"  - '{dup}' appears {short_name_counts[dup]} times")

        return self.mapping_dict

    def apply_capitalization_rules(self, text):
        """
        Apply specific capitalization rules to a text string:
        - Capitalize the first letter of every word, except for words starting with "al-"
        - For words starting with "al-", capitalize the letter after the hyphen
        - For words starting with hamzah (ʾ) or ʿayn (ʿ), capitalize the subsequent letter
        - Special case: If text is only "b." (with possible whitespace), keep it lowercase

        Args:
            text (str): The text to process

        Returns:
            str: The processed text with capitalization rules applied
        """
        if not isinstance(text, str) or not text:
            return text

        # Special case: Check if the text is just "b." (with possible whitespace)
        if text.strip() == "b.":
            return "b."

        # Split the text into words
        words = text.split()
        capitalized_words = []

        for i, word in enumerate(words):
            # Skip empty words
            if not word:
                continue

            # Special case: If this specific word is "b.", keep it lowercase
            if word == "b.":
                capitalized_word = "b."

            # Handle words beginning with "al-"
            elif word.lower().startswith("al-"):
                # Keep "al-" lowercase and capitalize the letter after the hyphen
                prefix = word[:3]  # "al-"
                rest = word[3:]

                if rest:
                    if rest[0] in 'ʾʿ' and len(rest) > 1:
                        # If the next character is hamzah or ʿayn, capitalize the letter after it
                        capitalized_word = prefix + rest[0] + rest[1].upper() + rest[2:]
                    else:
                        # Otherwise, capitalize the first letter after "al-"
                        capitalized_word = prefix + rest[0].upper() + rest[1:]
                else:
                    capitalized_word = prefix

            # Handle words beginning with hamzah or ʿayn
            elif word[0] in 'ʾʿ' and len(word) > 1:
                # Keep the first character (hamzah or ʿayn) and capitalize the next letter
                capitalized_word = word[0] + word[1].upper() + word[2:]

            # Handle other words (capitalize first letter)
            else:
                capitalized_word = word[0].upper() + word[1:] if word else word

            capitalized_words.append(capitalized_word)

        return ' '.join(capitalized_words)

    def name_replaces(self):
        """
        Replace names in the pathways with their mapped values and apply capitalization rules.

        Returns:
            DataFrame: DataFrame with replaced and properly capitalized names
        """
        if not self.time_columns:
            self.identify_time_columns()

        if not self.mapping_dict:
            self.create_mapping()

        # Create a copy of the original dataframe
        names_replaced_df = self.names_df.copy()

        # Process each time step column
        for col in self.time_columns:
            for idx, original_name in enumerate(self.names_df[col]):
                if pd.notna(original_name):
                    self.stats['total_names'] += 1

                    # Check if the name exists in our mapping
                    if original_name in self.mapping_dict:
                        # Replace with the corresponding name_replace
                        replaced_name = self.mapping_dict[original_name]

                        # Apply capitalization rules to the replaced name
                        capitalized_name = self.apply_capitalization_rules(replaced_name)

                        names_replaced_df.at[idx, col] = capitalized_name
                        self.stats['replaced_names'] += 1
                    else:
                        # For unmatched names, still apply capitalization rules
                        if isinstance(original_name, str):
                            names_replaced_df.at[idx, col] = self.apply_capitalization_rules(original_name)

                        # Keep track of unmatched names
                        self.stats['unmatched_names'].add(str(original_name))

        print(f"Replaced {self.stats['replaced_names']} of {self.stats['total_names']} names")
        print(f"Found {len(self.stats['unmatched_names'])} unique unmatched names")

        return names_replaced_df

    def save_results(self, names_replaced_df):
        """
        Save the results to files.

        Args:
            names_replaced_df (DataFrame): DataFrame with replaced names

        Returns:
            bool: True if successful, False otherwise
        """
        try:
            # Save the replaced names
            names_replaced_df.to_csv(self.output_file, index=False)
            print(f"Saved replaced names to {self.output_file}")

            # Save the unmatched names
            if self.stats['unmatched_names']:
                unmatched_file = 'unmatched_names.txt'
                with open(unmatched_file, 'w') as f:
                    for name in sorted(self.stats['unmatched_names']):
                        f.write(f"{name}\n")
                print(f"Saved {len(self.stats['unmatched_names'])} unmatched names to {unmatched_file}")

            return True
        except Exception as e:
            print(f"Error saving results: {e}")
            return False

    def analyze_network(self):
        """
        Analyze the network structure and provide insights.

        Returns:
            dict: Dictionary with network statistics
        """
        if not self.time_columns:
            self.identify_time_columns()

        # Initialize network statistics
        network_stats = {
            'pathway_count': len(self.names_df),
            'time_steps': len(self.time_columns),
            'node_counts_by_time': {},
            'total_unique_nodes': set(),
            'pathway_lengths': []
        }

        # Analyze each pathway
        for _, pathway in self.names_df.iterrows():
            # Count nodes in this pathway
            nodes_in_pathway = 0
            for col in self.time_columns:
                if pd.notna(pathway[col]):
                    nodes_in_pathway += 1
                    network_stats['total_unique_nodes'].add(pathway[col])

                    # Count nodes by time step
                    if col not in network_stats['node_counts_by_time']:
                        network_stats['node_counts_by_time'][col] = 0
                    network_stats['node_counts_by_time'][col] += 1

            network_stats['pathway_lengths'].append(nodes_in_pathway)

        # Calculate statistics about pathway lengths
        lengths = network_stats['pathway_lengths']
        network_stats['avg_pathway_length'] = np.mean(lengths)
        network_stats['min_pathway_length'] = np.min(lengths)
        network_stats['max_pathway_length'] = np.max(lengths)
        network_stats['total_unique_nodes'] = len(network_stats['total_unique_nodes'])

        # Log the statistics
        print(f"Network Analysis:")
        print(f"- {network_stats['pathway_count']} pathways over {network_stats['time_steps']} time steps")
        print(f"- {network_stats['total_unique_nodes']} unique nodes in the network")
        print(f"- Pathway lengths: avg={network_stats['avg_pathway_length']:.1f}, min={network_stats['min_pathway_length']}, max={network_stats['max_pathway_length']}")

        return network_stats

    def process(self):
        """
        Run the complete processing pipeline.

        Returns:
            bool: True if successful, False otherwise
        """
        if not self.load_data():
            return False

        # Analyze the network (optional but useful)
        self.analyze_network()

        # Replace names
        names_replaced_df = self.name_replaces()

        # Save results
        return self.save_results(names_replaced_df)


# This is the function you'll call directly in Colab
def process_network_names(names_file='names.csv', nodelist_file='nodelist.csv', output_file='names_replaced.csv'):
    """
    Process network names using the NetworkNameProcessor.

    Args:
        names_file (str): Path to the names CSV file
        nodelist_file (str): Path to the nodelist CSV file
        output_file (str): Path to the output CSV file

    Returns:
        DataFrame: The processed DataFrame with replaced names
    """
    # Initialize and run the processor
    processor = NetworkNameProcessor(names_file, nodelist_file, output_file)
    success = processor.process()

    if success:
        print("\nProcessing completed successfully")

        # Print summary
        print("\nSummary:")
        print(f"- Total names processed: {processor.stats['total_names']}")
        print(f"- Names successfully replaced: {processor.stats['replaced_names']}")
        print(f"- Names not found in mapping: {len(processor.stats['unmatched_names'])}")

        # Show examples of unmatched names
        if processor.stats['unmatched_names']:
            print("\nSample of unmatched names:")
            for name in sorted(list(processor.stats['unmatched_names']))[:10]:  # Show up to 10 examples
                print(f"- {name}")
            print(f"\nComplete list saved to 'unmatched_names.txt'")

        print(f"\nReplaced names saved to '{output_file}'")

        # Return the processed dataframe for further use in Colab
        return pd.read_csv(output_file)
    else:
        print("Processing failed")
        return None

if __name__ == "__main__":
     process_network_names()